<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>regression</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statopia</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Multivariant models</li>
    <li>
      <a href="LDA.html">LDA model</a>
    </li>
    <li>
      <a href="Clustering.html">Clustering models</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Univariant models</li>
    <li>
      <a href="regression.html">Advanced regression models</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">regression</h1>

</div>


<div id="general-linear-model" class="section level1">
<h1>General Linear Model</h1>
</div>
<div id="poisson-model" class="section level1">
<h1>Poisson Model</h1>
<p>For modelling the number of times an event occurs in an interval of time or space. like number of people, number of cases, and so forth.</p>
<p>To create our model we will use the total number of roadkills of amphibious along a roadway in Portugal (Zuur et al. 2013). We will take one explanatory variable into account for our analysis. We want to associate the distance to a park with the number of total roadkills (D.PARK).</p>
<p><img src="regression_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>knitr::kable(RK[1:10,])</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">Sector</th>
<th align="right">X</th>
<th align="right">Y</th>
<th align="right">BufoCalamita</th>
<th align="right">TOT.N</th>
<th align="right">S.RICH</th>
<th align="right">OPEN.L</th>
<th align="right">OLIVE</th>
<th align="right">MONT.S</th>
<th align="right">MONT</th>
<th align="right">POLIC</th>
<th align="right">SHRUB</th>
<th align="right">URBAN</th>
<th align="right">WAT.RES</th>
<th align="right">L.WAT.C</th>
<th align="right">L.D.ROAD</th>
<th align="right">L.P.ROAD</th>
<th align="right">D.WAT.RES</th>
<th align="right">D.WAT.COUR</th>
<th align="right">D.PARK</th>
<th align="right">N.PATCH</th>
<th align="right">P.EDGE</th>
<th align="right">L.SDI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">260181</td>
<td align="right">256546</td>
<td align="right">5</td>
<td align="right">22</td>
<td align="right">3</td>
<td align="right">22.684</td>
<td align="right">60.333</td>
<td align="right">0.000</td>
<td align="right">0.653</td>
<td align="right">4.811</td>
<td align="right">0.406</td>
<td align="right">7.787</td>
<td align="right">0.043</td>
<td align="right">0.583</td>
<td align="right">3330.189</td>
<td align="right">1.975</td>
<td align="right">252.113</td>
<td align="right">735.000</td>
<td align="right">250.214</td>
<td align="right">122</td>
<td align="right">553.936</td>
<td align="right">1.801</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">259914</td>
<td align="right">256124</td>
<td align="right">1</td>
<td align="right">14</td>
<td align="right">4</td>
<td align="right">24.657</td>
<td align="right">40.832</td>
<td align="right">0.000</td>
<td align="right">0.161</td>
<td align="right">2.224</td>
<td align="right">0.735</td>
<td align="right">27.150</td>
<td align="right">0.182</td>
<td align="right">1.419</td>
<td align="right">2587.498</td>
<td align="right">1.761</td>
<td align="right">139.573</td>
<td align="right">134.052</td>
<td align="right">741.179</td>
<td align="right">96</td>
<td align="right">457.142</td>
<td align="right">1.886</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">259672</td>
<td align="right">255688</td>
<td align="right">40</td>
<td align="right">65</td>
<td align="right">6</td>
<td align="right">30.121</td>
<td align="right">23.710</td>
<td align="right">0.258</td>
<td align="right">10.918</td>
<td align="right">1.946</td>
<td align="right">0.474</td>
<td align="right">28.086</td>
<td align="right">0.453</td>
<td align="right">2.005</td>
<td align="right">2149.651</td>
<td align="right">1.250</td>
<td align="right">59.168</td>
<td align="right">269.029</td>
<td align="right">1240.080</td>
<td align="right">67</td>
<td align="right">432.360</td>
<td align="right">1.930</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">259454</td>
<td align="right">255238</td>
<td align="right">27</td>
<td align="right">55</td>
<td align="right">5</td>
<td align="right">50.277</td>
<td align="right">14.940</td>
<td align="right">1.783</td>
<td align="right">26.454</td>
<td align="right">0.625</td>
<td align="right">0.607</td>
<td align="right">0.831</td>
<td align="right">0.026</td>
<td align="right">1.924</td>
<td align="right">4222.983</td>
<td align="right">0.666</td>
<td align="right">277.842</td>
<td align="right">48.751</td>
<td align="right">1739.885</td>
<td align="right">63</td>
<td align="right">421.292</td>
<td align="right">1.865</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">259307</td>
<td align="right">254763</td>
<td align="right">67</td>
<td align="right">88</td>
<td align="right">4</td>
<td align="right">43.609</td>
<td align="right">35.353</td>
<td align="right">2.431</td>
<td align="right">11.330</td>
<td align="right">0.791</td>
<td align="right">0.173</td>
<td align="right">2.452</td>
<td align="right">0.000</td>
<td align="right">2.167</td>
<td align="right">2219.302</td>
<td align="right">0.653</td>
<td align="right">967.808</td>
<td align="right">126.102</td>
<td align="right">2232.130</td>
<td align="right">59</td>
<td align="right">407.573</td>
<td align="right">1.818</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">259189</td>
<td align="right">254277</td>
<td align="right">56</td>
<td align="right">104</td>
<td align="right">7</td>
<td align="right">31.385</td>
<td align="right">17.666</td>
<td align="right">0.000</td>
<td align="right">43.678</td>
<td align="right">0.054</td>
<td align="right">0.325</td>
<td align="right">2.730</td>
<td align="right">0.039</td>
<td align="right">2.391</td>
<td align="right">1005.629</td>
<td align="right">1.309</td>
<td align="right">560.000</td>
<td align="right">344.444</td>
<td align="right">2724.089</td>
<td align="right">49</td>
<td align="right">420.289</td>
<td align="right">1.799</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">259092</td>
<td align="right">253786</td>
<td align="right">27</td>
<td align="right">49</td>
<td align="right">7</td>
<td align="right">24.810</td>
<td align="right">9.786</td>
<td align="right">0.000</td>
<td align="right">60.660</td>
<td align="right">0.022</td>
<td align="right">0.055</td>
<td align="right">1.001</td>
<td align="right">0.114</td>
<td align="right">1.165</td>
<td align="right">3735.189</td>
<td align="right">0.685</td>
<td align="right">93.147</td>
<td align="right">95.133</td>
<td align="right">3215.511</td>
<td align="right">35</td>
<td align="right">298.617</td>
<td align="right">1.593</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">258993</td>
<td align="right">253296</td>
<td align="right">37</td>
<td align="right">66</td>
<td align="right">7</td>
<td align="right">56.228</td>
<td align="right">1.619</td>
<td align="right">0.000</td>
<td align="right">25.280</td>
<td align="right">11.263</td>
<td align="right">0.092</td>
<td align="right">0.083</td>
<td align="right">0.224</td>
<td align="right">2.428</td>
<td align="right">4891.466</td>
<td align="right">0.677</td>
<td align="right">88.971</td>
<td align="right">243.230</td>
<td align="right">3709.401</td>
<td align="right">55</td>
<td align="right">442.750</td>
<td align="right">1.627</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">258880</td>
<td align="right">252809</td>
<td align="right">8</td>
<td align="right">26</td>
<td align="right">7</td>
<td align="right">48.735</td>
<td align="right">0.603</td>
<td align="right">1.108</td>
<td align="right">41.722</td>
<td align="right">1.238</td>
<td align="right">1.744</td>
<td align="right">0.185</td>
<td align="right">0.177</td>
<td align="right">2.416</td>
<td align="right">4010.961</td>
<td align="right">0.664</td>
<td align="right">684.887</td>
<td align="right">187.084</td>
<td align="right">4206.477</td>
<td align="right">52</td>
<td align="right">431.084</td>
<td align="right">1.801</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">258767</td>
<td align="right">252322</td>
<td align="right">16</td>
<td align="right">47</td>
<td align="right">6</td>
<td align="right">15.633</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">82.069</td>
<td align="right">0.119</td>
<td align="right">0.000</td>
<td align="right">0.361</td>
<td align="right">0.000</td>
<td align="right">0.211</td>
<td align="right">2885.246</td>
<td align="right">0.654</td>
<td align="right">794.000</td>
<td align="right">236.004</td>
<td align="right">4704.176</td>
<td align="right">26</td>
<td align="right">220.231</td>
<td align="right">1.440</td>
</tr>
</tbody>
</table>
<p>The data clearly presents a <strong>Poisson distribution</strong>.</p>
<div id="creation-of-the-glm-model" class="section level2">
<h2>1. Creation of the GLM model</h2>
<pre class="r"><code>M1 &lt;- glm(TOT.N ~ D.PARK, family = poisson, data = RK) 
summary(M1)</code></pre>
<pre><code>## 
## Call:
## glm(formula = TOT.N ~ D.PARK, family = poisson, data = RK)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -8.1100  -1.6950  -0.4708   1.4206   7.3337  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.316e+00  4.322e-02   99.87   &lt;2e-16 ***
## D.PARK      -1.059e-04  4.387e-06  -24.13   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1071.4  on 51  degrees of freedom
## Residual deviance:  390.9  on 50  degrees of freedom
## AIC: 634.29
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>100 * (1071.4 - 390.9)/ 1071.4</code></pre>
<pre><code>## [1] 63.51503</code></pre>
<p>The slope and the intercept of the model are statistically significants (p &lt; 0.001). The AIC value is 634.29 (we’ll need it to compare it with other models in the future). We can explain a 63% of the variance with our GLM model.</p>
</div>
<div id="plotting-the-model" class="section level2">
<h2>2. Plotting the model</h2>
<pre class="r"><code>MyData &lt;- data.frame(D.PARK = seq(from = 0, to = 25000, by = 1000))
G &lt;- predict(M1, newdata = MyData, type = &quot;link&quot;, se = TRUE)
Fi &lt;- exp(G$fit)

FSEUP &lt;- exp(G$fit + 1.96 * G$se.fit)
FSELOW &lt;- exp(G$fit - 1.96 * G$se.fit)
plot(RK$D.PARK, RK$TOT.N, 
     xlab = &quot;Distance to the park&quot;, ylab = &quot;Killroads&quot;)
lines(MyData$D.PARK, Fi,lty = 1)
lines(MyData$D.PARK, FSEUP, lty = 2, col = &quot;grey&quot;)
lines(MyData$D.PARK, FSELOW, lty = 2, col = &quot;grey&quot;)</code></pre>
<p><img src="regression_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="variable-selection" class="section level2">
<h2>3. Variable selection</h2>
<p>First of all, we have to transform the variables which has outliers. We will use a square transformation. Then, we will create a GLM model with a Poisson distribution without interactions</p>
<pre class="r"><code>RK$SQ.POLIC &lt;- sqrt(RK$POLIC)
RK$SQ.WATRES &lt;- sqrt(RK$WAT.RES)
RK$SQ.LPROAD &lt;- sqrt(RK$L.P.ROAD)
RK$SQ.SHRUB &lt;- sqrt(RK$SHRUB)
RK$SQ.DWATCOUR &lt;- sqrt(RK$D.WAT.COUR)

M2 &lt;- glm(TOT.N ~ OPEN.L + MONT.S + SQ.POLIC +
          SQ.SHRUB + SQ.WATRES + L.WAT.C + SQ.LPROAD +
          SQ.DWATCOUR + D.PARK, family = poisson, data = RK)
summary(M2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + SQ.SHRUB + 
##     SQ.WATRES + L.WAT.C + SQ.LPROAD + SQ.DWATCOUR + D.PARK, family = poisson, 
##     data = RK)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.8398  -1.3965  -0.1409   1.4641   4.3749  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.749e+00  1.567e-01  23.935  &lt; 2e-16 ***
## OPEN.L      -3.025e-03  1.580e-03  -1.915 0.055531 .  
## MONT.S       8.697e-02  1.359e-02   6.398 1.57e-10 ***
## SQ.POLIC    -1.787e-01  4.676e-02  -3.822 0.000133 ***
## SQ.SHRUB    -6.112e-01  1.176e-01  -5.197 2.02e-07 ***
## SQ.WATRES    2.243e-01  7.050e-02   3.181 0.001468 ** 
## L.WAT.C      3.355e-01  4.127e-02   8.128 4.36e-16 ***
## SQ.LPROAD    4.517e-01  1.348e-01   3.351 0.000804 ***
## SQ.DWATCOUR  7.355e-03  4.879e-03   1.508 0.131629    
## D.PARK      -1.301e-04  5.936e-06 -21.923  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1071.44  on 51  degrees of freedom
## Residual deviance:  270.23  on 42  degrees of freedom
## AIC: 529.62
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>There are no significant variables. In order to decide which variables we have to eliminate we will use two kinds of selections: 1. Step method using both forward and step methods 2. Manual analysis</p>
<div id="step-method" class="section level3">
<h3>3.1. Step method</h3>
<ol style="list-style-type: decimal">
<li>Forward</li>
</ol>
<pre class="r"><code>summary(step(M2, trace = 0))</code></pre>
<pre><code>## 
## Call:
## glm(formula = TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + SQ.SHRUB + 
##     SQ.WATRES + L.WAT.C + SQ.LPROAD + SQ.DWATCOUR + D.PARK, family = poisson, 
##     data = RK)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.8398  -1.3965  -0.1409   1.4641   4.3749  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.749e+00  1.567e-01  23.935  &lt; 2e-16 ***
## OPEN.L      -3.025e-03  1.580e-03  -1.915 0.055531 .  
## MONT.S       8.697e-02  1.359e-02   6.398 1.57e-10 ***
## SQ.POLIC    -1.787e-01  4.676e-02  -3.822 0.000133 ***
## SQ.SHRUB    -6.112e-01  1.176e-01  -5.197 2.02e-07 ***
## SQ.WATRES    2.243e-01  7.050e-02   3.181 0.001468 ** 
## L.WAT.C      3.355e-01  4.127e-02   8.128 4.36e-16 ***
## SQ.LPROAD    4.517e-01  1.348e-01   3.351 0.000804 ***
## SQ.DWATCOUR  7.355e-03  4.879e-03   1.508 0.131629    
## D.PARK      -1.301e-04  5.936e-06 -21.923  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1071.44  on 51  degrees of freedom
## Residual deviance:  270.23  on 42  degrees of freedom
## AIC: 529.62
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Drop</li>
</ol>
<pre class="r"><code>drop1(M2, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Single term deletions
## 
## Model:
## TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + SQ.SHRUB + SQ.WATRES + L.WAT.C + 
##     SQ.LPROAD + SQ.DWATCOUR + D.PARK
##             Df Deviance     AIC    LRT  Pr(&gt;Chi)    
## &lt;none&gt;           270.23  529.62                     
## OPEN.L       1   273.93  531.32   3.69 0.0546474 .  
## MONT.S       1   306.89  564.28  36.66 1.410e-09 ***
## SQ.POLIC     1   285.53  542.92  15.30 9.181e-05 ***
## SQ.SHRUB     1   298.31  555.70  28.08 1.167e-07 ***
## SQ.WATRES    1   280.02  537.41   9.79 0.0017539 ** 
## L.WAT.C      1   335.47  592.86  65.23 6.648e-16 ***
## SQ.LPROAD    1   281.25  538.64  11.02 0.0009009 ***
## SQ.DWATCOUR  1   272.50  529.89   2.27 0.1319862    
## D.PARK       1   838.09 1095.48 567.85 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We should eliminate the SQ.DWATCOUR variable.</p>
<pre class="r"><code>M2b&lt;-glm(TOT.N~OPEN.L + MONT.S + SQ.POLIC +
           SQ.SHRUB + SQ.WATRES + L.WAT.C + SQ.LPROAD+
           D.PARK, family = poisson, data = RK)
summary(M2b)</code></pre>
<pre><code>## 
## Call:
## glm(formula = TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + SQ.SHRUB + 
##     SQ.WATRES + L.WAT.C + SQ.LPROAD + D.PARK, family = poisson, 
##     data = RK)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -7.1443  -1.4118  -0.3607   1.3934   4.3559  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.852e+00  1.405e-01  27.405  &lt; 2e-16 ***
## OPEN.L      -3.464e-03  1.544e-03  -2.243 0.024890 *  
## MONT.S       8.927e-02  1.344e-02   6.643 3.08e-11 ***
## SQ.POLIC    -1.583e-01  4.492e-02  -3.525 0.000424 ***
## SQ.SHRUB    -6.160e-01  1.185e-01  -5.200 2.00e-07 ***
## SQ.WATRES    2.080e-01  6.917e-02   3.006 0.002645 ** 
## L.WAT.C      3.113e-01  3.817e-02   8.155 3.50e-16 ***
## SQ.LPROAD    4.936e-01  1.315e-01   3.753 0.000175 ***
## D.PARK      -1.286e-04  5.837e-06 -22.033  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1071.4  on 51  degrees of freedom
## Residual deviance:  272.5  on 43  degrees of freedom
## AIC: 529.89
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Now all the variables are statiscally significants.</p>
</div>
<div id="manual-analysis" class="section level3">
<h3>3.2. Manual analysis</h3>
<pre class="r"><code>anova(M2, M2b, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + SQ.SHRUB + SQ.WATRES + L.WAT.C + 
##     SQ.LPROAD + SQ.DWATCOUR + D.PARK
## Model 2: TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + SQ.SHRUB + SQ.WATRES + L.WAT.C + 
##     SQ.LPROAD + D.PARK
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1        42     270.23                     
## 2        43     272.50 -1   -2.269    0.132</code></pre>
<p>There are no significant differences between the two models (p=0.132, Dif deviance=2.269) We will continue our analysis with the model without the SQ.DWATCOUR variable, since this is the most parsimonious model.</p>
<pre class="´r"><code>M3 &lt;- glm(TOT.N ~ MONT.S + SQ.POLIC + D.PARK +
            SQ.SHRUB + SQ.WATRES + L.WAT.C + SQ.LPROAD +
            SQ.DWATCOUR, family = poisson, data = RK)
anova(M2, M3, test = &quot;Chi&quot;)</code></pre>
</div>
</div>
<div id="overdispersion" class="section level2">
<h2>4- Overdispersion</h2>
<p>This problem happens when the variance is greater than the mean. A value greater than 1 would mean a problem.</p>
<pre class="r"><code>270.23/42</code></pre>
<pre><code>## [1] 6.434048</code></pre>
</div>
<div id="validation" class="section level2">
<h2>5- Validation</h2>
<pre class="r"><code>op &lt;- par(mfrow = c(2, 2))
plot(M2b)</code></pre>
<p><img src="regression_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>EP &lt;- resid(M2b, type = &quot;pearson&quot;)
ED &lt;- resid(M2b, type = &quot;deviance&quot;)
par(op)

mu &lt;- predict(M2b, type = &quot;response&quot;)
E &lt;- RK$TOT.N - mu
EP2 &lt;- E/sqrt(6.337209 * mu)

op &lt;- par(mfrow=c(2,2))
plot(x = mu, y = E, main = &quot;Response residuals&quot;)
plot(x = mu, y = EP, main = &quot;Pearson residuals&quot;)
plot(x = mu, y = EP2, main = &quot;Pearson residuals scaled&quot;)
plot(x = mu, y = ED, main = &quot;Deviance residuals&quot;)</code></pre>
<p><img src="regression_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<pre class="r"><code>par(op)</code></pre>
<p>We observe an anormal ditribution of the residuals. Probably this is due to the overdispersion problem. We try to fix it with another distribution: the negative binomial.</p>
</div>
</div>
<div id="binomial-negative-distribution" class="section level1">
<h1>Binomial negative distribution</h1>
<div id="model-creation" class="section level2">
<h2>1- Model creation</h2>
<pre class="r"><code>library(MASS)</code></pre>
<pre><code>## Warning: package &#39;MASS&#39; was built under R version 3.4.4</code></pre>
<pre class="r"><code>M6 &lt;- glm.nb(TOT.N ~ OPEN.L + MONT.S + SQ.POLIC +
             SQ.SHRUB + SQ.WATRES + L.WAT.C + SQ.LPROAD +
             SQ.DWATCOUR + D.PARK, link = &quot;log&quot;, data = RK)
summary(M6, cor = FALSE)</code></pre>
<pre><code>## 
## Call:
## glm.nb(formula = TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + SQ.SHRUB + 
##     SQ.WATRES + L.WAT.C + SQ.LPROAD + SQ.DWATCOUR + D.PARK, data = RK, 
##     link = &quot;log&quot;, init.theta = 5.517795385)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.97265  -0.64463  -0.03337   0.62007   1.48627  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.951e+00  4.145e-01   9.532   &lt;2e-16 ***
## OPEN.L      -9.419e-03  3.245e-03  -2.903   0.0037 ** 
## MONT.S       5.846e-02  3.481e-02   1.679   0.0931 .  
## SQ.POLIC    -4.618e-02  1.298e-01  -0.356   0.7221    
## SQ.SHRUB    -3.881e-01  2.883e-01  -1.346   0.1784    
## SQ.WATRES    1.631e-01  1.675e-01   0.974   0.3301    
## L.WAT.C      2.076e-01  9.636e-02   2.154   0.0312 *  
## SQ.LPROAD    5.944e-01  3.214e-01   1.850   0.0644 .  
## SQ.DWATCOUR -1.489e-05  1.139e-02  -0.001   0.9990    
## D.PARK      -1.235e-04  1.292e-05  -9.557   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(5.5178) family taken to be 1)
## 
##     Null deviance: 213.674  on 51  degrees of freedom
## Residual deviance:  51.803  on 42  degrees of freedom
## AIC: 390.11
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  5.52 
##           Std. Err.:  1.41 
## 
##  2 x log-likelihood:  -368.107</code></pre>
</div>
<div id="variables-selection" class="section level2">
<h2>2- Variables selection</h2>
<div id="step-method-1" class="section level3">
<h3>2.1. Step method</h3>
<pre class="r"><code>summary(step(M6, trace = 0))</code></pre>
<pre><code>## 
## Call:
## glm.nb(formula = TOT.N ~ OPEN.L + L.WAT.C + SQ.LPROAD + D.PARK, 
##     data = RK, init.theta = 4.979895134, link = &quot;log&quot;)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -3.08218  -0.70494  -0.09268   0.55575   1.67860  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.032e+00  3.363e-01  11.989  &lt; 2e-16 ***
## OPEN.L      -1.085e-02  3.122e-03  -3.475  0.00051 ***
## L.WAT.C      1.597e-01  7.852e-02   2.034  0.04195 *  
## SQ.LPROAD    4.924e-01  3.101e-01   1.588  0.11231    
## D.PARK      -1.154e-04  1.061e-05 -10.878  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(4.9799) family taken to be 1)
## 
##     Null deviance: 197.574  on 51  degrees of freedom
## Residual deviance:  51.329  on 47  degrees of freedom
## AIC: 383.54
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  4.98 
##           Std. Err.:  1.22 
## 
##  2 x log-likelihood:  -371.542</code></pre>
<pre class="r"><code>summary(stepAIC(M6, trace = 0))</code></pre>
<pre><code>## 
## Call:
## glm.nb(formula = TOT.N ~ OPEN.L + L.WAT.C + SQ.LPROAD + D.PARK, 
##     data = RK, init.theta = 4.979895134, link = &quot;log&quot;)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -3.08218  -0.70494  -0.09268   0.55575   1.67860  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.032e+00  3.363e-01  11.989  &lt; 2e-16 ***
## OPEN.L      -1.085e-02  3.122e-03  -3.475  0.00051 ***
## L.WAT.C      1.597e-01  7.852e-02   2.034  0.04195 *  
## SQ.LPROAD    4.924e-01  3.101e-01   1.588  0.11231    
## D.PARK      -1.154e-04  1.061e-05 -10.878  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(4.9799) family taken to be 1)
## 
##     Null deviance: 197.574  on 51  degrees of freedom
## Residual deviance:  51.329  on 47  degrees of freedom
## AIC: 383.54
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  4.98 
##           Std. Err.:  1.22 
## 
##  2 x log-likelihood:  -371.542</code></pre>
<p>Both methods suggets the variables OPEN.L, L.WAT.C, SQ.LPROAD y D.PARK. The variable SQ.LPROAD is not significant and L.WAT.C is slightly significant.</p>
</div>
<div id="drop-method" class="section level3">
<h3>2.2. Drop method</h3>
<pre class="r"><code>M7 &lt;- glm.nb(TOT.N ~ OPEN.L + L.WAT.C + SQ.LPROAD + D.PARK, link = &quot;log&quot;, data = RK)
drop1(M7, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Single term deletions
## 
## Model:
## TOT.N ~ OPEN.L + L.WAT.C + SQ.LPROAD + D.PARK
##           Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## &lt;none&gt;         51.329 381.54                      
## OPEN.L     1   63.331 391.54  12.002 0.0005316 ***
## L.WAT.C    1   55.384 383.60   4.055 0.0440383 *  
## SQ.LPROAD  1   54.086 382.30   2.757 0.0968442 .  
## D.PARK     1  172.847 501.06 121.518 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We should eliminate both variables to improve our model.</p>
</div>
<div id="manual-analysis-1" class="section level3">
<h3>2.3. Manual analysis</h3>
<pre class="r"><code>M7b &lt;- glm.nb(TOT.N ~ OPEN.L + L.WAT.C + D.PARK,link = &quot;log&quot;, data = RK)
M7c &lt;- glm.nb(TOT.N ~ OPEN.L + D.PARK, link = &quot;log&quot;, data = RK)
anova(M7b, M7c)</code></pre>
<pre><code>## Likelihood ratio tests of Negative Binomial Models
## 
## Response: TOT.N
##                       Model    theta Resid. df    2 x log-lik.   Test
## 1           OPEN.L + D.PARK 4.132845        49       -379.4317       
## 2 OPEN.L + L.WAT.C + D.PARK 4.725770        48       -374.2536 1 vs 2
##      df LR stat.    Pr(Chi)
## 1                          
## 2     1 5.178081 0.02287358</code></pre>
</div>
</div>
<div id="overdispersion-1" class="section level2">
<h2>3- Overdispersion</h2>
<pre class="r"><code>summary(M7c)</code></pre>
<pre><code>## 
## Call:
## glm.nb(formula = TOT.N ~ OPEN.L + D.PARK, data = RK, link = &quot;log&quot;, 
##     init.theta = 4.13284466)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.5880  -0.7878  -0.1676   0.3721   2.4369  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.6717034  0.1641768  28.455   &lt;2e-16 ***
## OPEN.L      -0.0093591  0.0031952  -2.929   0.0034 ** 
## D.PARK      -0.0001119  0.0000113  -9.901   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(4.1328) family taken to be 1)
## 
##     Null deviance: 170.661  on 51  degrees of freedom
## Residual deviance:  51.839  on 49  degrees of freedom
## AIC: 387.43
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  4.133 
##           Std. Err.:  0.980 
## 
##  2 x log-likelihood:  -379.432</code></pre>
<pre class="r"><code>51.839/49</code></pre>
<pre><code>## [1] 1.057939</code></pre>
<p>Close to 1, so it is not supposed to be a problem.</p>
</div>
<div id="validation-1" class="section level2">
<h2>4- Validation</h2>
<pre class="r"><code>M8 &lt;- glm.nb(TOT.N ~ OPEN.L + D.PARK, link = &quot;log&quot;, data = RK)
summary(M8)</code></pre>
<pre><code>## 
## Call:
## glm.nb(formula = TOT.N ~ OPEN.L + D.PARK, data = RK, link = &quot;log&quot;, 
##     init.theta = 4.13284466)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.5880  -0.7878  -0.1676   0.3721   2.4369  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.6717034  0.1641768  28.455   &lt;2e-16 ***
## OPEN.L      -0.0093591  0.0031952  -2.929   0.0034 ** 
## D.PARK      -0.0001119  0.0000113  -9.901   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(4.1328) family taken to be 1)
## 
##     Null deviance: 170.661  on 51  degrees of freedom
## Residual deviance:  51.839  on 49  degrees of freedom
## AIC: 387.43
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  4.133 
##           Std. Err.:  0.980 
## 
##  2 x log-likelihood:  -379.432</code></pre>
<pre class="r"><code>drop1(M8, test = &quot;Chi&quot;)</code></pre>
<pre><code>## Single term deletions
## 
## Model:
## TOT.N ~ OPEN.L + D.PARK
##        Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## &lt;none&gt;      51.839 385.43                      
## OPEN.L  1   59.731 391.32   7.891  0.004967 ** 
## D.PARK  1  154.595 486.19 102.756 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Both variables are significant.</p>
<pre class="r"><code>par(mfrow = c(2, 2))
plot(M8)</code></pre>
<p><img src="regression_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>There is no problem with the model.</p>
</div>
<div id="interpretation" class="section level2">
<h2>5- Interpretation</h2>
<p>The farther from the park (D.PARK), the lesser the number of roadkills (TOT.N). In addition to this, the open spaces (OPEN.L) are significantly the safest.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
